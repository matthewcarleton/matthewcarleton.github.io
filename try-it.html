---
layout: default
title: Try it
permalink: /try-it.html
---
<div class="mk-masthead__content--sub">
        <h1 class="mk-masthead__content--sub__title">Getting started with Metal3.io</h1>
        <p class="mk-masthead__content--sub__text">Ready to start taking steps towards your first experience with metal3.io? Follow these commands to get started! </p>
</div>
</section>
<main class="mk-main mk-main__homepage">
    <aside class="mk-main__aside">
        <header class="mk-main__header">
          <h2 class="mk-heading mk-heading--xl mk-m-border">Metal³ Development Environment</h2>
        </header>
        <ul>
          <li><a href="#instructions">Instructions</a>
          <ul>
            <li><a href="#prerequisites">Prerequisites</a></li>
            <li><a href="#setup">Setup</a></li>
          </ul>
          </li>
          <li><a href="#environment">Working with the environment</a>
          <ul>
            <li><a href="#baremetalhosts">Bare Metal Hosts</a></li>
            <li><a href="#provisioningmachine">Provisioning a Machine</a></li>
            <li><a href="#provisioningbmh">Directly Provisioning Bare Metal Hosts</a></li>
            <li><a href="#baremetaloperator">Running a Custom baremetal-operator</a></li>
            <li><a href="#customapiprovider">Running a Custom cluster-api-provider-baremetal</a></li>
            <li><a href="#ironicapi">Accessing the Ironic API</a></li>
          </ul>
          </li>
        </ul>
    </aside>
  <div class="mk-main__content">
      <section class="mk-why-metalkubed mk-main__section">
          <header class="mk-main__header">
          <h2 id="instructions" class="mk-heading mk-heading--xl mk-m-border">Instructions</h2>
          </header>
          <div class="mk-main__section__content">
              <h3 id="prerequisites" class="mk-heading mk-heading--lg">Prerequisites</h3>
              <ul>
                <li>System with CentOS 7 or Ubuntu 18.04</li>
                <li>Bare metal preferred, as we will be creating VMs to emulate bare metal hosts</li>
                <li>run as a user with passwordless sudo access</li>
              </ul>
              <h3 id="setup" class="mk-heading mk-heading--lg">Setup</h3>
              <p>tl;dr - Run <code>make</code>.</p>
              <p>The <code>Makefile</code> runs a series of scripts, described here:</p>
              <ul>
                <li><code>01_install_requirements.sh</code> - Installs all needed packages.</li>
                <li><code>02_configure_host.sh</code> - Create a set of VMs that will be managed as if they were bare metal hosts.</li>
                <li><code>03_launch_mgmt_cluster.sh</code> - Launch a management cluster using minikube and run the baremetal-operator on that cluster.</li>
              </ul>
               <p>To tear down the environment, run <code>make clean</code>.</p>
              
               <h3 class="mk-heading mk-heading--lg">Note</h3>
              <p>If you see this error during the installation:</p>
              
              <p><pre class="mk-code-block">
error: failed to connect to the hypervisor</br>
error: Failed to connect socket to '/var/run/libvirt/libvirt-sock': Permission denied
              </pre>
            </p>
              <p>You may need to log out then login again, and run <code>make</code> again.</p>
          </div>
       </section>
        <section class="mk-why-metalkubed mk-main__section">
           <header class="mk-main__header">
           <h2 id="environment" class="mk-heading mk-heading--xl mk-m-border">Working with the environment</h2>
           </header>
<div class="mk-main__section__content">
<h3 id="baremetalhosts" class="mk-heading mk-heading--lg">Bare Metal Hosts</h3>
<p>This environment creates a set of VMs to manage as if they were bare metal hosts. You can see the VMs using <code>virsh</code>.</p>
<p>
<pre class="mk-code-block">
$ sudo virsh list
Id    Name                           State
----------------------------------------------------
6     minikube                       running
9     kube_worker_0                  running
10    kube_master_0                  running
</pre>       
</p>
  
<p>Each of the VMs (aside from the <code>minikube</code> management cluster VM) are represented by <code>BareMetalHost</code> objects in our management cluster. The yaml used to create these host objects is in <code>bmhosts_crs.yaml</code>.</p>
<p>
<pre class="mk-code-block">
$ kubectl get baremetalhosts -n metal3
NAME       STATUS    PROVISIONING STATUS   MACHINE   BMC                         HARDWARE PROFILE   ONLINE    ERROR
master-0   OK        ready                           ipmi://192.168.111.1:6230   unknown            true      
worker-0   OK        ready                           ipmi://192.168.111.1:6231   unknown            true      
You can also look at the details of a host, including the hardware information gathered by doing pre-deployment introspection.

$ kubectl get baremetalhost -n metal3 -oyaml worker-0
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"metal3.io/v1alpha1","kind":"BareMetalHost","metadata":{"annotations":{},"name":"worker-0","namespace":"metal3"},"spec":{"bmc":{"address":"ipmi://192.168.111.1:6231","credentialsName":"worker-0-bmc-secret"},"bootMACAddress":"00:c2:fc:3b:8e:b5","online":true}}
  creationTimestamp: 2019-05-27T14:16:07Z
  finalizers:
  - baremetalhost.metal3.io
  generation: 2
  name: worker-0
  namespace: metal3
  resourceVersion: "1180"
  selfLink: /apis/metal3.io/v1alpha1/namespaces/metal3/baremetalhosts/worker-0
  uid: f878526e-8089-11e9-93f1-3c93b777d2dc
spec:
  bmc:
    address: ipmi://192.168.111.1:6231
    credentialsName: worker-0-bmc-secret
  bootMACAddress: 00:c2:fc:3b:8e:b5
  description: ""
  hardwareProfile: ""
  online: true
status:
  errorMessage: ""
  goodCredentials:
    credentials:
      name: worker-0-bmc-secret
      namespace: metal3
    credentialsVersion: "802"
  hardware:
    cpu:
      count: 4
      model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz
      speedGHz: 2.199996
      type: x86_64
    nics:
    - ip: 192.168.111.21
      mac: 00:c2:fc:3b:8e:b7
      model: 0x1af4 0x0001
      name: eth1
      network: Pod Networking
      speedGbps: 0
    - ip: 172.22.0.32
      mac: 00:c2:fc:3b:8e:b5
      model: 0x1af4 0x0001
      name: eth0
      network: Pod Networking
      speedGbps: 0
    ramGiB: 7
    storage:
    - hctl: "2:0:0:0"
      model: QEMU HARDDISK
      name: /dev/sda
      serialNumber: drive-scsi0-0-0-0
      sizeGiB: 50
      type: HDD
      vendor: QEMU
    systemVendor:
      manufacturer: Red Hat
      productName: KVM
      serialNumber: ""
  hardwareProfile: unknown
  lastUpdated: 2019-05-27T14:20:27Z
  operationalStatus: OK
  poweredOn: true
  provisioning:
    ID: 36dac1b9-a2ec-40b0-98b7-89dc13ca6e29
    image:
      checksum: ""
      url: ""
    state: ready    
</pre>
</p>
<h3 id="provisioningmachine" class="mk-heading mk-heading--lg">Provisioning a Machine</h3>
<p>This section describes how to trigger provisioning of a host via <code>Machine</code> objects as part of the <code>cluster-api</code> integration.</p>
<p>First, run the <code>create_machine.sh</code> script to create a <code>Machine</code>. The argument is a name, and does not have any special meaning.</p> 
<p>
<pre class="mk-code-block">
$ ./create_machine.sh centos

secret/centos-user-data created
machine.cluster.k8s.io/centos created
</pre>
</p>
  <p>At this point, the <code>Machine</code> actuator will respond and try to claim a <code>BareMetalHost</code> for this <code>Machine</code>. You can check the logs of the actuator here:</p>
  <p>
<pre class="mk-code-block">
$ kubectl logs -n metal3 pod/cluster-api-provider-baremetal-controller-manager-0 -c manager

{“level”:”info”,”ts”:1557509343.85325,”logger”:”baremetal-controller-manager”,”msg”:”Found API group metal3.io/v1alpha1”}
{“level”:”info”,”ts”:1557509344.0471826,”logger”:”kubebuilder.controller”,”msg”:”Starting EventSource”,”controller”:”machine-controller”,”source”:”kind source: /, Kind=”}
{“level”:”info”,”ts”:1557509344.14783,”logger”:”kubebuilder.controller”,”msg”:”Starting Controller”,”controller”:”machine-controller”}
{“level”:”info”,”ts”:1557509344.248105,”logger”:”kubebuilder.controller”,”msg”:”Starting workers”,”controller”:”machine-controller”,”worker count”:1}
2019/05/10 17:32:33 Checking if machine centos exists.
2019/05/10 17:32:33 Machine centos does not exist.
2019/05/10 17:32:33 Creating machine centos .
2019/05/10 17:32:33 2 hosts available
2019/05/10 17:32:33 Associating machine centos with host worker-0
2019/05/10 17:32:33 Finished creating machine centos .
2019/05/10 17:32:33 Checking if machine centos exists.
2019/05/10 17:32:33 Machine centos exists.
2019/05/10 17:32:33 Updating machine centos .
2019/05/10 17:32:33 Finished updating machine centos .
</pre>
</p>
<p>If you look at the yaml representation of the <code>Machine</code>, you will see a new annotation that identifies which <code>BareMetalHost</code> was chosen to satisfy this <code>Machine</code> request.</p>
<p>
<pre class="mk-code-block">
$ kubectl get machine centos -n metal3 -o yaml
...
annotations:
metal3.io/BareMetalHost: metal3/worker-0
...
</pre>
</p>
<p>You can also see in the list of <code>BareMetalHost</code> that one of the hosts is now provisioned and associated with a <code>Machine</code>.</p>
<p>
<pre class="mk-code-block">
$ kubectl get baremetalhosts -n metal3

NAME       STATUS    PROVISIONING STATUS   MACHINE   BMC                         HARDWARE PROFILE   ONLINE    ERROR
master-0   OK        ready                           ipmi://192.168.111.1:6230   unknown            true      
worker-0   OK        provisioning          centos    ipmi://192.168.111.1:6231   unknown            true
</pre>      
</p>
<p>You should be able to ssh into your host once provisioning is complete. See the libvirt DHCP leases to find the IP address for the host that was provisioned. In this case, it’s <code>worker-0</code>.</p>
<p>
<pre class="mk-code-block">
$ sudo virsh net-dhcp-leases baremetal
Expiry Time          MAC address        Protocol  IP address                Hostname        Client ID or DUID
-------------------------------------------------------------------------------------------------------------------
  2019-05-06 19:03:46  00:1c:cc:c6:29:39  ipv4      192.168.111.20/24         master-0        -
  2019-05-06 19:04:18  00:1c:cc:c6:29:3d  ipv4      192.168.111.21/24         worker-0        -
</pre>
</p>
<p>The default user for the CentOS image is <code>centos</code>.</p>
<p><pre class="mk-code-block">ssh centos@192.168.111.21</pre></p>
<p>Deprovisioning is done just by deleting the <code>Machine</code> object.</p>
<p>
 <pre class="mk-code-block">
$ kubectl delete machine centos -n metal3
machine.cluster.k8s.io "centos" deleted
 </pre> 
</p>
<p>At this point you can see that the <code>BareMetalHost</code> is going through a deprovisioning process.</p>
<p>
<pre class="mk-code-block">
$ kubectl get baremetalhosts -n metal3

NAME       STATUS   PROVISIONING STATUS   MACHINE   BMC                         HARDWARE PROFILE   ONLINE   ERROR
master-0   OK       ready                           ipmi://192.168.111.1:6230   unknown            true     
worker-0   OK       deprovisioning                  ipmi://192.168.111.1:6231   unknown            false  
</pre>             
</p>
<h3 id="provisioningbmh" class="mk-heading mk-heading--lg">Directly Provisioning Bare Metal Hosts</h3>
<p>It’s also possible to provision via the <code>BareMetalHost</code> interface directly without using the <code>cluster-api</code> integration.</p>

<p>There is a helper script available to trigger provisioning of one of these hosts. To provision a host with CentOS 7, run:</p>
<p class="mk-code-block">$ ./provision_host.sh worker-0</p>

<p>The <code>BareMetalHost</code> will go through the provisioning process, and will eventually reboot into the operating system we wrote to disk.</p>
<p>
<pre class="mk-code-block">
$ kubectl get baremetalhost worker-0 -n metal3
NAME       STATUS   PROVISIONING STATUS   MACHINE   BMC                         HARDWARE PROFILE   ONLINE   ERROR
worker-0   OK       provisioned                     ipmi://192.168.111.1:6231   unknown            true    
</pre>
</p>
<p><code>provision_host.sh</code> will inject your SSH public key into the VM. To find the IP address, you can check the DHCP leases on the <code>baremetal</code> libvirt network.</p>
<p>
<pre class="mk-code-block">
$ sudo virsh net-dhcp-leases baremetal
Expiry Time          MAC address        Protocol  IP address                Hostname        Client ID or DUID
-------------------------------------------------------------------------------------------------------------------
  2019-05-06 19:03:46  00:1c:cc:c6:29:39  ipv4      192.168.111.20/24         master-0        -
  2019-05-06 19:04:18  00:1c:cc:c6:29:3d  ipv4      192.168.111.21/24         worker-0        -
</pre> 
</p>

<p>The default user for the CentOS image is <code>centos</code>.</p>

<p class="mk-code-block">ssh centos@192.168.111.21</p>
<p>There is another helper script to deprovision a host.</p>

<p class="mk-code-block">$ ./deprovision_host.sh worker-0</p>
<p>You will then see the host go into a <code>deprovisioning</code> status:</p>
<p>
<pre class="mk-code-block">
$ kubectl get baremetalhost worker-0 -n metal3
NAME       STATUS   PROVISIONING STATUS   MACHINE   BMC                         HARDWARE PROFILE   ONLINE   ERROR
worker-0   OK       deprovisioning                  ipmi://192.168.111.1:6231   unknown            true
</pre>  
</p>

<h3 id="baremetaloperator" class="mk-heading mk-heading--xl">Running a Custom baremetal-operator</h3>
<p>The <code>baremetal-operator</code> comes up running in the cluster by default, using an image built from the <code>metal3-io/baremetal-operator</code> github repository. If you’d like to test changes to the <code>baremetal-operator</code>, you can follow this process.</p>

<p>First, you must scale down the deployment of the <code>baremetal-operator</code> running in the cluster.</p>

<p class="mk-code-block">kubectl scale deployment metal3-baremetal-operator -n metal3 --replicas=0</p>
<p>To be able to run <code>baremetal-operator</code> locally, you need to install <code>operator-sdk</code> <a href=""https://github.com/operator-framework">https://github.com/operator-framework</a>. After that, you can run the <code>baremetal-operator</code> including any custom changes.</p>
<p>
<pre class="mk-code-block">
cd ~/go/src/github.com/metal3-io/baremetal-operator
make run
</pre></p>

<h3 id="customapiprovider" class="mk-heading mk-heading--xl">Running a Custom cluster-api-provider-baremetal</h3>
<p>There are two cluster-api related managers running in the cluster. One includes set of generic controllers, and the other includes a custom Machine controller for baremetal. If you want to try changes to <code>cluster-api-provider-baremetal</code>, you want to shut down the custom Machine controller manager first.</p>

<p><pre class="mk-code-block">
  $ kubectl scale statefulset cluster-api-provider-baremetal-controller-manager -n metal3 --replicas=0
</pre>
</p>
<p>Then you can run the custom Machine controller manager out of your local git tree.</p>
<p>
<pre class="mk-code-block">
cd ~/go/src/github.com/metal3-io/cluster-api-provider-baremetal
make run
</pre>  
</p>
<h3 id="ironicapi" class="mk-heading mk-heading--xl">Accessing the Ironic API</h3>
<p>Sometimes you may want to look directly at Ironic to debug something. You can do this with the <code>openstack</code> command.</p>
<p>First you must set these environment variables:</p>
<p>
<pre class="mk-code-block">
export OS_TOKEN=fake-token
export OS_URL=http://localhost:6385/  
</pre>  
</p>
<p>Example:</p>
<p>
<pre class="mk-code-block">
$ openstack baremetal node list
+--------------------------------------+----------+---------------+-------------+--------------------+-------------+
| UUID                                 | Name     | Instance UUID | Power State | Provisioning State | Maintenance |
+--------------------------------------+----------+---------------+-------------+--------------------+-------------+
| 882cf206-d688-43fa-bf4c-3282fcb00b12 | master-0 | None          | None        | enroll             | False       |
| ac257479-d6c6-47c1-a649-64a88e6ff312 | worker-0 | None          | None        | enroll             | False       |
+--------------------------------------+---------------+---------------+-------------+--------------------+-------------+
</pre>
</p>
</div>
</section>
</div>    
</main>